{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, openai\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import text, create_engine\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentService:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        self.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        # Get database password from environment variable\n",
    "        self.engine = create_engine(f'postgresql://postgres:{os.getenv(\"POSTGRES_PASSWORD\")}@localhost:5432/pdf_db')\n",
    "\n",
    "    def detect_malicious_intent(self, question):\n",
    "        \"\"\"Uses OpenAI's moderation model to detect malicious intent in a question.\"\"\"\n",
    "        try:\n",
    "            response = openai.moderations.create(\n",
    "                model=\"text-moderation-latest\",\n",
    "                input=question,\n",
    "            )\n",
    "            is_flagged = response.results[0].flagged\n",
    "            return is_flagged, \"This question has been flagged for malicious content and cannot be processed.\" if is_flagged else \"No malicious intent detected.\"\n",
    "        except Exception as e:\n",
    "            return None, f\"Error in moderation: {str(e).split('. ')[0]}.\"\n",
    "        \n",
    "    def query_database(self, query):\n",
    "        \"\"\"Executes a given query on the database.\"\"\"\n",
    "        with self.engine.connect() as connection:\n",
    "            result = connection.execute(text(query)).fetchone()\n",
    "            return result if result else None\n",
    "    \n",
    "    def question_to_embeddings(self, question):\n",
    "        \"\"\"Converts a question to embeddings.\"\"\"\n",
    "        try:\n",
    "            response = openai.embeddings.create(input=question, model=\"text-embedding-3-large\")\n",
    "            embedded_query = response.data[0].embedding\n",
    "            # Ensure the embedding matches the expected dimensionality of 3072\n",
    "            if len(embedded_query) != 3072:\n",
    "                raise ValueError(\"The dimensionality of the question embedding does not match the expected 3072 dimensions.\")\n",
    "            else:\n",
    "                question_vectorized = np.array(embedded_query, dtype=np.float64).tolist()\n",
    "                return question_vectorized\n",
    "        except Exception as e:\n",
    "            print(f\"Error embedding the question: {e}\")\n",
    "            return [] # Return an empty list if no data is found in the response\n",
    "\n",
    "    def check_relatedness_to_pdf_content(self, question):\n",
    "        \"\"\"Checks if the question is related to the PDF content by querying a database.\"\"\"\n",
    "        question_vectorized = self.question_to_embeddings(question)\n",
    "\n",
    "        try:\n",
    "\n",
    "            with self.engine.connect() as conn:\n",
    "                # Use the vector in your query with the <=> operator for cosine distance\n",
    "                result = conn.execute(text(\"\"\"\n",
    "                    SELECT id, text, embedding <=> CAST(:question_vector AS VECTOR) AS distance \n",
    "                    FROM pdf_holder\n",
    "                    ORDER BY distance ASC\n",
    "                    LIMIT 1;\n",
    "                \"\"\"), {'question_vector': question_vectorized}).fetchone()\n",
    "\n",
    "                if result:\n",
    "                    closest_id, _, distance = result\n",
    "                    threshold = 0.5  # albritrary threshold that works well with my PDF, needs to test it out accordingly \n",
    "                    if distance < threshold:\n",
    "                        return True, \"Question is related to the PDF content.\"\n",
    "                    else:\n",
    "                        return False, \"Question is not related to the PDF content.\"\n",
    "                else:\n",
    "                    return False, \"No match found in the database.\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching the database: {e}\")\n",
    "            return False, f\"Error searching the database: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intent_orchestrator(service):\n",
    "    \"\"\"Orchestrates the process of checking if a question is related to any PDF content.\"\"\"\n",
    "\n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        question = input(\"Enter your question or type 'exit' to quit: \").strip()\n",
    "        if question.lower() == 'exit':\n",
    "            print(\"Exiting...\")\n",
    "            return None\n",
    "        \n",
    "\n",
    "        is_flagged, message = service.detect_malicious_intent(question)\n",
    "        print(message)\n",
    "        if is_flagged or is_flagged is None:  # Continue loop if flagged or an error occurred\n",
    "            continue\n",
    "\n",
    "        related, message = service.check_relatedness_to_pdf_content(question)\n",
    "        print(message)\n",
    "        vectorized_question = service.question_to_embeddings(question)\n",
    "        if related:\n",
    "            return vectorized_question, question\n",
    "        else:\n",
    "            print(\"Please try a different question...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_question():\n",
    "    \"\"\"Main function to start the question processing workflow.\"\"\"\n",
    "    service = IntentService()\n",
    "    vectorized_question, question = intent_orchestrator(service)\n",
    "    if not vectorized_question:\n",
    "        print(\"No question was processed successfully.\")\n",
    "    else:\n",
    "        return vectorized_question, question"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
