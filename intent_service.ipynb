{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, nltk, os, openai, spacy, glob\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from autocorrect import Speller\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from information_retrieval_service import InformationRetrievalService\n",
    "from sqlalchemy import text, create_engine\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sternsemasuka/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sternsemasuka/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sternsemasuka/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentService:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        self.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        self.spell_checker = Speller()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "        self.information_retrieval_service = InformationRetrievalService()\n",
    "\n",
    "    def preprocess_question(self, question):\n",
    "        \"\"\"Preprocesses the input question by performing lowercasing, removing punctuation,\n",
    "        tokenizing, removing stopwords, stemming, lemmatizing, and spelling correction.\"\"\"\n",
    "        question = question.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "        tokens = [self.stemmer.stem(word) for word in word_tokenize(question) if word not in self.stop_words]\n",
    "        lemmas = [self.nlp(word)[0].lemma_ for word in tokens]\n",
    "        revised_tokens = [self.spell_checker(token.text) if \"not_\" not in token.dep_ else \"not_\" + token.text for token in self.nlp(' '.join(lemmas))]\n",
    "        return ' '.join(revised_tokens).strip()\n",
    "\n",
    "    def detect_malicious_intent(self, question):\n",
    "        \"\"\"Uses OpenAI's moderation model to detect malicious intent in a question.\"\"\"\n",
    "        try:\n",
    "            response = openai.moderations.create(\n",
    "                model=\"text-moderation-latest\",\n",
    "                input=question,\n",
    "            )\n",
    "            is_flagged = response.results[0].flagged\n",
    "            return is_flagged, \"This question has been flagged for malicious content and cannot be processed.\" if is_flagged else \"No malicious intent detected.\"\n",
    "        except Exception as e:\n",
    "            return None, f\"Error in moderation: {str(e).split('. ')[0]}.\"\n",
    "\n",
    "    def check_relatedness_to_pdf_content(self, question):\n",
    "        \"\"\"Checks if the question is related to the PDF content by querying a database.\"\"\"\n",
    "        question_vectorized = self.information_retrieval_service.question_to_embeddings(question)\n",
    "\n",
    "        try:\n",
    "            # Directly use the question_vectorized array for querying\n",
    "            with self.information_retrieval_service.engine.connect() as conn:\n",
    "                # Adjust your query to use an array parameter for vector comparison\n",
    "                result = conn.execute(text(\"\"\"\n",
    "                    SELECT id, text, embedding <-> :question_vector AS distance\n",
    "                    FROM pdf_holder\n",
    "                    ORDER BY distance ASC\n",
    "                    LIMIT 1;\n",
    "                \"\"\"), {'question_vector': question_vectorized}).fetchone()\n",
    "\n",
    "                if result:\n",
    "                    closest_id, _, distance = result\n",
    "                    print(f\"Closest match ID: {closest_id}, Distance: {distance}\")\n",
    "                    threshold = 0.5  # Adjust threshold as needed\n",
    "                    if distance < threshold:\n",
    "                        print(\"Question is related to the PDF content.\")\n",
    "                        return True\n",
    "                    else:\n",
    "                        print(\"Question is not related to the PDF content.\")\n",
    "                        return False\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching the database: {e}\")\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InformationRetrievalService:\n",
    "    def __init__(self):\n",
    "        # Get database password from environment variable\n",
    "        self.engine = create_engine(f'postgresql://postgres:{os.getenv(\"POSTGRES_PASSWORD\")}@localhost:5432/pdf_db')\n",
    "\n",
    "    def question_to_embeddings(self, question):\n",
    "        \"\"\"Converts a question to embeddings.\"\"\"\n",
    "        try:\n",
    "            response = openai.embeddings.create(input=question, model=\"text-embedding-3-large\")\n",
    "            embedded_query = response.data[0].embedding\n",
    "            # Ensure the embedding matches the expected dimensionality of 3072\n",
    "            if len(embedded_query) != 3072:\n",
    "                raise ValueError(\"The dimensionality of the question embedding does not match the expected 3072 dimensions.\")\n",
    "            else:\n",
    "                question_vectorized = np.array(embedded_query, dtype=np.float64).tolist()\n",
    "                return question_vectorized\n",
    "        except Exception as e:\n",
    "            print(f\"Error embedding the question: {e}\")\n",
    "            return [] # Return an empty list if no data is found in the response\n",
    "\n",
    "    def query_database(self, query):\n",
    "        \"\"\"Executes a given query on the database.\"\"\"\n",
    "        with self.engine.connect() as connection:\n",
    "            result = connection.execute(text(query)).fetchone()\n",
    "            return result if result else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intent_orchestrator(service):\n",
    "    \"\"\"Orchestrates the process of checking if a question is related to any PDF content.\"\"\"\n",
    "    DIRECTORY_PATH = '/Users/sternsemasuka/Desktop/ML/Project/Talk-to-your-PDF/pdf_folder/'\n",
    "    pdf_file_path = glob.glob(os.path.join(DIRECTORY_PATH, '*.pdf'))\n",
    "    if not pdf_file_path:\n",
    "        print(\"No PDF files found in the specified directory.\")\n",
    "        return None\n",
    "\n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        question = input(\"Enter your question or type 'exit' to quit: \").strip()\n",
    "        if question.lower() == 'exit':\n",
    "            print(\"Exiting...\")\n",
    "            return None\n",
    "\n",
    "        is_flagged, message = service.detect_malicious_intent(question)\n",
    "        print(message)\n",
    "        if is_flagged or is_flagged is None:  # Continue loop if flagged or an error occurred\n",
    "            continue\n",
    "\n",
    "        related, message = service.check_relatedness_to_pdf_content(question)\n",
    "        print(message)\n",
    "        if related:\n",
    "            return question, pdf_file_path\n",
    "        else:\n",
    "            print(\"Please try a different question...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No malicious intent detected.\n",
      "Error searching the database: (psycopg2.errors.UndefinedFunction) operator does not exist: vector <-> numeric[]\n",
      "LINE 2:                     SELECT id, text, embedding <-> ARRAY[ -0...\n",
      "                                                       ^\n",
      "HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.\n",
      "\n",
      "[SQL: \n",
      "                    SELECT id, text, embedding <-> %(question_vector)s AS distance\n",
      "                    FROM pdf_holder\n",
      "                    ORDER BY distance ASC\n",
      "                    LIMIT 1;\n",
      "                ]\n",
      "[parameters: {'question_vector': [-0.0012315254425629973, -0.026523638516664505, -0.0388735830783844, -0.008712361566722393, 0.00020783541549462825, 0.035741496831178665, -0.029992725 ... (68623 characters truncated) ... 1190165132284, 0.0038333397824317217, -0.022717555984854698, 0.007433755323290825, 0.023550137877464294, -0.00288181914947927, -0.0008338195621035993]}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable bool object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     12\u001b[0m     openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Ensure OpenAI API key is set globally for the session\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     process_user_question()\n",
      "Cell \u001b[0;32mIn[82], line 4\u001b[0m, in \u001b[0;36mprocess_user_question\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Main function to start the question processing workflow.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m service \u001b[38;5;241m=\u001b[39m IntentService()\n\u001b[0;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m intent_orchestrator(service)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m      6\u001b[0m     question, pdf_file_path \u001b[38;5;241m=\u001b[39m result\n",
      "Cell \u001b[0;32mIn[81], line 21\u001b[0m, in \u001b[0;36mintent_orchestrator\u001b[0;34m(service)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_flagged \u001b[38;5;129;01mor\u001b[39;00m is_flagged \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Continue loop if flagged or an error occurred\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m related, message \u001b[38;5;241m=\u001b[39m service\u001b[38;5;241m.\u001b[39mcheck_relatedness_to_pdf_content(question)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(message)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m related:\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable bool object"
     ]
    }
   ],
   "source": [
    "def process_user_question():\n",
    "    \"\"\"Main function to start the question processing workflow.\"\"\"\n",
    "    service = IntentService()\n",
    "    result = intent_orchestrator(service)\n",
    "    if result:\n",
    "        question, pdf_file_path = result\n",
    "        print(f\"Question: '{question}' is processed and related to the PDF at '{pdf_file_path}'.\")\n",
    "    else:\n",
    "        print(\"No question was processed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # Ensure OpenAI API key is set globally for the session\n",
    "    process_user_question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
