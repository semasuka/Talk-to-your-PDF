{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, nltk, os, openai, spacy, glob, import_ipynb\n",
    "from dotenv import load_dotenv\n",
    "from autocorrect import Speller\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from information_retrieval_service import InformationRetrievalService\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sternsemasuka/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sternsemasuka/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sternsemasuka/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentService:\n",
    "    def __init__(self):\n",
    "        # Load environment variables from .env file\n",
    "        load_dotenv()\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        self.spell_checker = Speller()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "        # initialization of the self from InformationRetrievalService class\n",
    "        self.information_retrieval_service = InformationRetrievalService()\n",
    "\n",
    "    def preprocess_question(self, question):\n",
    "        # Lowercase\n",
    "        question = question.lower()\n",
    "        # Remove punctuation and special characters\n",
    "        question = question.translate(str.maketrans('', '', string.punctuation))\n",
    "        # Tokenization\n",
    "        tokens = word_tokenize(question)\n",
    "        # Stop words removal\n",
    "        tokens = [word for word in tokens if word not in self.stop_words]\n",
    "        # Stemming and Lemmatization\n",
    "        tokens = [self.stemmer.stem(word) for word in tokens]\n",
    "        tokens = [self.nlp(word)[0].lemma_ for word in tokens]\n",
    "        # Negation tracking, POS tagging, NER, and spelling correction\n",
    "        revised_tokens = []\n",
    "        doc = self.nlp(' '.join(tokens))\n",
    "        for token in doc:\n",
    "            # Correct spelling\n",
    "            corrected_word = self.spell_checker(token.text)\n",
    "            # Handle negation\n",
    "            if \"not_\" in token.dep_:\n",
    "                corrected_word = \"not_\" + corrected_word\n",
    "            # POS tagging and NER are included in the Spacy pipeline\n",
    "            revised_tokens.append(corrected_word)\n",
    "        # Rejoin tokens and trim spaces\n",
    "        question = ' '.join(revised_tokens).strip()\n",
    "        print(\"preliminary preprocessing completed...\")\n",
    "        return question\n",
    "    \n",
    "    def detect_malicious_intent(self, question):\n",
    "        is_flagged = None\n",
    "        try:\n",
    "            # Calling the openai moderation model \n",
    "            response = openai.moderations.create(\n",
    "                model=\"text-moderation-latest\",\n",
    "                input=question,\n",
    "            )\n",
    "            # checking if it is flagged or not\n",
    "            is_flagged = response.results[0].flagged\n",
    "            \n",
    "            if is_flagged:\n",
    "                print(\"This question has been flagged for malicious content and cannot be processed.\")\n",
    "            else:\n",
    "                print(\"No malicious intent detected...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in moderation: {e} Unable to determine intent due to an error.\")\n",
    "        return is_flagged\n",
    "\n",
    "    def check_relatedness_to_pdf_content(self, question):\n",
    "        # class the InformationRetrievalService's question_to_embeddings method\n",
    "        question_vectorized = self.information_retrieval_service.question_to_embeddings(question)\n",
    "        \n",
    "        try:\n",
    "            # Convert question_embedding to PostgreSQL array format, ensuring it matches the expected dimension\n",
    "            question_vector = '{' + ','.join(map(str, question_vectorized)) + '}'\n",
    "            \n",
    "            with self.information_retrieval_service.engine.connect() as conn:\n",
    "                result = conn.execute(text(\"\"\"\n",
    "                    SELECT id, text, embedding <-> :question_vector AS distance\n",
    "                    FROM item\n",
    "                    ORDER BY distance ASC\n",
    "                    LIMIT 1;\n",
    "                \"\"\"), {'question_vector': question_vector}).fetchone()\n",
    "                \n",
    "                if result:\n",
    "                    closest_id, _, distance = result\n",
    "                    print(f\"Closest match ID: {closest_id}, Distance: {distance}\")\n",
    "                    print(\"%\" * 10)\n",
    "                    # Adjust threshold based on your use case\n",
    "                    threshold = 0.5  # Example threshold\n",
    "                    if distance < threshold:\n",
    "                        print(\"Question is related to the PDF content.\")\n",
    "                        return True\n",
    "                    else:\n",
    "                        print(\"Question is not related to the PDF content.\")\n",
    "                        return False\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching the database: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def check_item_status(self,is_question_related, is_flagged):\n",
    "        match (is_question_related, is_flagged):\n",
    "            case (True, False):\n",
    "                print(\"The question is related to the PDF and not flagged. We can proceed...\")\n",
    "                return True\n",
    "\n",
    "            case (False, True):\n",
    "                print(\"The question is not related to the PDF and has been flagged, therefore cannot proceed. Please try a different question...\")\n",
    "                return False\n",
    "            \n",
    "            case (True, True):\n",
    "                print(\"The question is related to the PDF however has been flagged, thus cannot proceed. Please try a different question...\")\n",
    "                return False\n",
    "            \n",
    "            case (False, False):\n",
    "                print(\"The question is not related to the PDF nor flagged. Please try a different question...\")\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intent_orchestrator(input_question, service):\n",
    "    DIRECTORY_PATH = '/Users/sternsemasuka/Desktop/ML/Project/Talk-to-your-PDF/pdf_folder/'\n",
    "    pdf_file_paths = glob.glob(os.path.join(DIRECTORY_PATH, '*.pdf'))\n",
    "    if not pdf_file_paths:\n",
    "        print(\"No PDF files found in the specified directory.\")\n",
    "        return False, None, None  # Adjusted to return a consistent number of values\n",
    "\n",
    "    pdf_file_path = pdf_file_paths[0]\n",
    "    \n",
    "    while True:  # Loop to continuously ask for input if flagged for malicious intent\n",
    "        preprocessed_question = service.preprocess_question(input_question)\n",
    "        is_flagged = service.detect_malicious_intent(preprocessed_question)\n",
    "        \n",
    "        if is_flagged:\n",
    "            print(\"Please input another question as the previous one was flagged for malicious content.\")\n",
    "            input_question = input(\"Enter your question or type 'exit' to quit: \")  # Prompt for a new question\n",
    "            if input_question.lower() == 'exit':\n",
    "                print(\"Exiting... Thank you for using the system.\")\n",
    "                return False, None, None  # Exiting the loop and function\n",
    "        else:\n",
    "            break  # Exit the loop if the question is not flagged\n",
    "\n",
    "    # Proceed to check the relatedness only if the question is not flagged\n",
    "    is_question_related = service.check_relatedness_to_pdf_content(preprocessed_question)\n",
    "    can_proceed = service.check_item_status(is_question_related, is_flagged)\n",
    "    return can_proceed, preprocessed_question, pdf_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_pipeline(service):\n",
    "    while True:\n",
    "        question = input(\"Enter your question or type 'exit' to quit: \")\n",
    "        if question.lower() == 'exit':\n",
    "            print(\"Exiting... Thank you for using the system.\")\n",
    "            return None  # Return None to indicate the user chose to exit\n",
    "        else:\n",
    "            can_proceed, preprocessed_question, pdf_file_path = intent_orchestrator(question, service)\n",
    "            if can_proceed:\n",
    "                print(\"Question processed successfully...\")\n",
    "                return preprocessed_question, pdf_file_path, question  # Return the preprocessed question\n",
    "            else:\n",
    "                print(\"Please try a different question...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_question():\n",
    "    service = IntentService()\n",
    "    result = question_pipeline(service)\n",
    "    if result:\n",
    "        preprocessed_question, pdf_file_path, question = result\n",
    "        print(\"Question preprocessed and ready for further actions.\")\n",
    "    else:\n",
    "        print(\"No question was preprocessed or processed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preliminary preprocessing completed...\n",
      "No malicious intent detected...\n",
      "Error searching the database: (psycopg2.errors.UndefinedTable) relation \"item\" does not exist\n",
      "LINE 3:                     FROM item\n",
      "                                 ^\n",
      "\n",
      "[SQL: \n",
      "                    SELECT id, text, embedding <-> %(question_vector)s AS distance\n",
      "                    FROM item\n",
      "                    ORDER BY distance ASC\n",
      "                    LIMIT 1;\n",
      "                ]\n",
      "[parameters: {'question_vector': '{-0.02843516133725643,-0.01720310188829899,-0.0014136313693597913,-0.03317435458302498,-0.027117768302559853,-0.03534719720482826,-0.0015697509516030 ... (65499 characters truncated) ... .006835046224296093,-0.01557774655520916,-0.016732605174183846,0.0074124750681221485,0.023559095337986946,-0.004330716095864773,0.007284157909452915}'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "The question is not related to the PDF nor flagged. Please try a different question...\n",
      "Please try a different question...\n",
      "preliminary preprocessing completed...\n",
      "This question has been flagged for malicious content and cannot be processed.\n",
      "Please input another question as the previous one was flagged for malicious content.\n",
      "preliminary preprocessing completed...\n",
      "This question has been flagged for malicious content and cannot be processed.\n",
      "Please input another question as the previous one was flagged for malicious content.\n",
      "preliminary preprocessing completed...\n",
      "No malicious intent detected...\n",
      "Error searching the database: (psycopg2.errors.UndefinedTable) relation \"item\" does not exist\n",
      "LINE 3:                     FROM item\n",
      "                                 ^\n",
      "\n",
      "[SQL: \n",
      "                    SELECT id, text, embedding <-> %(question_vector)s AS distance\n",
      "                    FROM item\n",
      "                    ORDER BY distance ASC\n",
      "                    LIMIT 1;\n",
      "                ]\n",
      "[parameters: {'question_vector': '{-0.010501068085432053,-0.02927570417523384,-0.020529361441731453,-0.006755232345312834,0.0019570172298699617,-0.016565321013331413,0.012055771425366 ... (65524 characters truncated) ... .012219424359500408,-0.015083352103829384,0.020329339429736137,-0.008132644928991795,0.021056687459349632,0.005586931947618723,-0.006487023551017046}'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "The question is not related to the PDF nor flagged. Please try a different question...\n",
      "Please try a different question...\n"
     ]
    }
   ],
   "source": [
    "process_user_question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
