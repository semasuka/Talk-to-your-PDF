{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import os, openai, glob\n",
    "from pdfminer.high_level import extract_text as pdf_extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataService:\n",
    "\n",
    "    def __init__(self):\n",
    "        # Load environment variables from .env file\n",
    "        load_dotenv()\n",
    "        # Get database password from environment variable\n",
    "        db_password = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        # SQLAlchemy engine\n",
    "        self.engine = create_engine(f'postgresql://postgres:{db_password}@localhost:5432/pdf_db')\n",
    "        self.Session = sessionmaker(bind=self.engine)\n",
    "\n",
    "    def pdf_to_embeddings(self, pdf_path: str, chunk_length: int = 1000):\n",
    "        chunks = []\n",
    "        # Extract text from PDF\n",
    "        text = pdf_extract_text(pdf_path)\n",
    "        chunks.extend([text[i:i+chunk_length].replace('\\n', '') for i in range(0, len(text), chunk_length)])\n",
    "        # Generate embeddings for each chunk of text\n",
    "        try:\n",
    "            # Accessing the latest embedding model\n",
    "            response = openai.embeddings.create(model='text-embedding-3-large', input=chunks)\n",
    "            # Accessing the embeddings directly from the response object\n",
    "            embeddings = []\n",
    "            for embedding_info in response.data:  \n",
    "                embedding_vector = embedding_info.embedding  # Access the embedding vector\n",
    "                index = embedding_info.index  # Access the index if needed\n",
    "                embeddings.append({\n",
    "                    'vector': embedding_vector,\n",
    "                    'text': chunks[index]  \n",
    "                })\n",
    "            return embeddings\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return []\n",
    "\n",
    "    def load_data_to_vector_store(self, embeddings):\n",
    "        session = self.Session()\n",
    "        try:\n",
    "            # Truncate the table before inserting new data\n",
    "            truncate_query = text(\"TRUNCATE TABLE pdf_holder RESTART IDENTITY\")\n",
    "            session.execute(truncate_query)\n",
    "\n",
    "            # Now, insert new data\n",
    "            for embedding in embeddings:\n",
    "                vector = np.array(embedding[\"vector\"], dtype=np.float64).tolist()\n",
    "                insert_query = text(\"INSERT INTO pdf_holder (text, embedding) VALUES (:text, :embedding)\")\n",
    "                session.execute(insert_query, {\"text\": embedding[\"text\"], \"embedding\": vector})\n",
    "            \n",
    "            session.commit()\n",
    "        except Exception as e:\n",
    "            session.rollback()  # Rollback in case of any error\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        finally:\n",
    "            session.close()  # Ensuring session is closed after operation\n",
    "\n",
    "    \n",
    "    def check_and_print_embeddings(self):\n",
    "        with self.engine.connect() as connection:\n",
    "            # Explicitly declare the query as text\n",
    "            query = text(\"SELECT id, text, embedding FROM pdf_holder\")\n",
    "            result = connection.execute(query)\n",
    "            for row in result:\n",
    "                print(f\"ID: {row.id}, Text: {row.text}, Embedding: {row.embedding}\")\n",
    "\n",
    "    def search_in_vector_store(self, user_query: str, k: int = 5):\n",
    "        # Creates embedding vector from user query/question\n",
    "        response = openai.embeddings.create(input=user_query, model=\"text-embedding-3-large\")\n",
    "        if response.data:\n",
    "            embedded_query = response.data[0].embedding\n",
    "            query_vector = np.array(embedded_query, dtype=np.float64).tolist()\n",
    "\n",
    "            # Using L2 distance for nearest neighbor search\n",
    "            sql_query = text(\"\"\"\n",
    "                            SELECT id, text, embedding <-> CAST(:query_vector AS VECTOR) AS distance\n",
    "                            FROM pdf_holder\n",
    "                            ORDER BY distance\n",
    "                            LIMIT :k\n",
    "                            \"\"\")\n",
    "            \n",
    "            with self.engine.connect() as conn:\n",
    "                results = conn.execute(sql_query, {'query_vector': query_vector, 'k': k}).fetchall()\n",
    "                # Convert results into a list of dictionaries\n",
    "                search_results = [\n",
    "                    {\"id\": row[0], \"text\": row[1], \"distance\": row[2]} \n",
    "                    for row in results\n",
    "                ]\n",
    "\n",
    "                return search_results\n",
    "        else:\n",
    "            return [] # Return an empty list if no data is found in the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory path\n",
    "DIRECTORY_PATH = '/Users/sternsemasuka/Desktop/ML/Project/Talk-to-your-PDF/' \n",
    "# Search for any PDF file in the directory\n",
    "pdf_file_path = glob.glob(os.path.join(DIRECTORY_PATH, '*.pdf'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_service_processor = DataService()\n",
    "# Embedding the pdf\n",
    "pdf_embedded = data_service_processor.pdf_to_embeddings(pdf_path = pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embedding into the vector store\n",
    "data_service_processor.load_data_to_vector_store(pdf_embedded)\n",
    "#data_service_processor.check_and_print_embeddings()\n",
    "search_results = data_service_processor.search_in_vector_store(user_query = 'main object canada nation digit talent strategy outline pdf')\n",
    "search_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
