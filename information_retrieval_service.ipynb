{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import os, openai\n",
    "from pdfminer.high_level import extract_text as pdf_extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InformationRetrievalService:\n",
    "\n",
    "    def __init__(self):\n",
    "        # Load environment variables from .env file\n",
    "        load_dotenv()\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        # Get database password from environment variable\n",
    "        db_password = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "        # SQLAlchemy engine\n",
    "        self.engine = create_engine(f'postgresql://postgres:{db_password}@localhost:5432/pdf_db')\n",
    "        self.Session = sessionmaker(bind=self.engine)\n",
    "\n",
    "    def pdf_to_embeddings(self, pdf_path: str, chunk_length: int = 1000):\n",
    "        chunks = []\n",
    "        # Extract text from PDF\n",
    "        text = pdf_extract_text(pdf_path)\n",
    "        chunks.extend([text[i:i+chunk_length].replace('\\n', '') for i in range(0, len(text), chunk_length)])\n",
    "        # Generate embeddings for each chunk of text\n",
    "        try:\n",
    "            # Accessing the latest embedding model\n",
    "            response = openai.embeddings.create(model='text-embedding-3-large', input=chunks)\n",
    "            # Accessing the embeddings directly from the response object\n",
    "            embeddings = []\n",
    "            for embedding_info in response.data:  \n",
    "                embedding_vector = embedding_info.embedding  # Access the embedding vector\n",
    "                index = embedding_info.index  # Access the index if needed\n",
    "                embeddings.append({\n",
    "                    'vector': embedding_vector,\n",
    "                    'text': chunks[index]  \n",
    "                })\n",
    "            return embeddings\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return []\n",
    "\n",
    "    def load_data_to_vector_store(self, embeddings):\n",
    "        session = self.Session()\n",
    "        try:\n",
    "            # Truncate the table before inserting new data\n",
    "            truncate_query = text(\"TRUNCATE TABLE pdf_holder RESTART IDENTITY\")\n",
    "            session.execute(truncate_query)\n",
    "\n",
    "            # Now, insert new data\n",
    "            for embedding in embeddings:\n",
    "                vector = np.array(embedding[\"vector\"], dtype=np.float64).tolist()\n",
    "                insert_query = text(\"INSERT INTO pdf_holder (text, embedding) VALUES (:text, :embedding)\")\n",
    "                session.execute(insert_query, {\"text\": embedding[\"text\"], \"embedding\": vector})\n",
    "            \n",
    "            session.commit()\n",
    "        except Exception as e:\n",
    "            session.rollback()  # Rollback in case of any error\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        finally:\n",
    "            session.close()  # Ensuring session is closed after operation\n",
    "\n",
    "    \n",
    "    def check_and_print_embeddings(self):\n",
    "        with self.engine.connect() as connection:\n",
    "            # Explicitly declare the query as text\n",
    "            query = text(\"SELECT id, text, embedding FROM pdf_holder\")\n",
    "            result = connection.execute(query)\n",
    "            for row in result:\n",
    "                print(f\"ID: {row.id}, Text: {row.text}, Embedding: {row.embedding}\")\n",
    "                \n",
    "    def question_to_embeddings(self, question: str):\n",
    "        # Creates embedding vector from user query/question\n",
    "        try:\n",
    "            response = openai.embeddings.create(input=question, model=\"text-embedding-3-large\")\n",
    "            embedded_query = response.data[0].embedding\n",
    "            # Ensure the embedding matches the expected dimensionality of 3072\n",
    "            if len(embedded_query) != 3072:\n",
    "                raise ValueError(\"The dimensionality of the question embedding does not match the expected 3072 dimensions.\")\n",
    "            else:\n",
    "                question_vectorized = np.array(embedded_query, dtype=np.float64).tolist()\n",
    "                return question_vectorized\n",
    "        except Exception as e:\n",
    "            print(f\"Error embedding the question: {e}\")\n",
    "            return [] # Return an empty list if no data is found in the response\n",
    "        \n",
    "    def search_in_vector_store(self, user_query, k: int = 1):\n",
    "        question_vectorized = self.question_to_embeddings(question = user_query)\n",
    "\n",
    "        if question_vectorized:\n",
    "            # Using cosine distance for nearest neighbor search\n",
    "            sql_query = text(\"\"\"\n",
    "                            SELECT id, text, embedding <=> CAST(:query_vector AS VECTOR) AS distance\n",
    "                            FROM pdf_holder\n",
    "                            ORDER BY distance\n",
    "                            LIMIT :k\n",
    "                            \"\"\")\n",
    "            \n",
    "            with self.engine.connect() as conn:\n",
    "                results = conn.execute(sql_query, {'query_vector': question_vectorized, 'k': k}).fetchall()\n",
    "                # Convert results into a list of dictionaries\n",
    "                search_results = [\n",
    "                    {\"id\": row[0], \"text\": row[1], \"distance\": row[2]} \n",
    "                    for row in results\n",
    "                ]\n",
    "\n",
    "                return search_results[0][\"text\"]\n",
    "        else:\n",
    "            print(\"No data found in your response\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_retrieval(preprocessed_question, pdf_file_path):\n",
    "    data_service_processor = InformationRetrievalService()\n",
    "    # Embedding the pdf\n",
    "    pdf_embedded = data_service_processor.pdf_to_embeddings(pdf_path = pdf_file_path)\n",
    "    # Load the embedding into the vector store\n",
    "    data_service_processor.load_data_to_vector_store(pdf_embedded)\n",
    "    #data_service_processor.check_and_print_embeddings()\n",
    "    search_results = data_service_processor.search_in_vector_store(user_query = preprocessed_question)\n",
    "    return search_results, preprocessed_question"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
